{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTvno11spxJT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
        "\n",
        "#Answer:\n",
        "\n",
        "In Python, both multithreading and multiprocessing offer ways to achieve parallelism, but they are suited for different types of tasks. The decision to use one over the other depends largely on the nature of the task and the limitations imposed by Python's Global Interpreter Lock (GIL).\n",
        "\n",
        "**1. When to Use Multithreading:**\n",
        "\n",
        "**Best for I/O-bound tasks:**\n",
        "\n",
        "Multithreading is well-suited for tasks that spend time waiting for input/output operations to complete, such as reading/writing files, network operations, or database queries. In these situations, threads can continue working while the program waits for the external resource, as the GIL is released during I/O waits.\n",
        "\n",
        "Examples:\n",
        "Web scraping, downloading data from the internet, or handling numerous incoming client connections in a web server.\n",
        "\n",
        "**Lower memory consumption:**\n",
        "\n",
        "Since threads within a process share the same memory space, they require less memory than processes, which operate in isolated memory spaces. This makes multithreading more efficient when memory is a concern.\n",
        "\n",
        "Example: Applications where multiple tasks need to run concurrently but don’t demand heavy memory usage, like keeping a user interface responsive while performing background tasks.\n",
        "\n",
        "**Cheaper task switching:**\n",
        "\n",
        "Switching between threads is typically faster than switching between processes because threads share resources, whereas processes need to maintain separate memory and system resources.\n",
        "\n",
        "**Real-time task responsiveness:**\n",
        "\n",
        "Multithreading helps maintain smooth performance in real-time applications, such as graphical user interfaces (GUIs), where some tasks can run in the background without interrupting the main program.\n",
        "\n",
        "**Ideal scenarios for multithreading:**\n",
        "\n",
        "Web servers managing multiple client connections.\n",
        "\n",
        "Applications where tasks spend significant time waiting on I/O operations, like network requests or file handling.\n",
        "\n",
        "\n",
        "**2.When to Use Multiprocessing:**\n",
        "\n",
        "\n",
        "**Ideal for CPU-bound tasks:**\n",
        "\n",
        "Multiprocessing excels in tasks that require significant computational power. In such cases, using multiple processes allows for true parallelism since each process runs independently with its own Python interpreter, bypassing the GIL.\n",
        "\n",
        "Examples:\n",
        "Computationally heavy operations like image processing, simulations, or data analysis.\n",
        "\n",
        "**Process isolation:**\n",
        "\n",
        "Processes do not share memory, which provides isolation between tasks. This isolation is useful when tasks are independent or when you want to prevent one task from affecting others in case of failure or errors.\n",
        "\n",
        "Example:\n",
        "Running isolated computations or tasks that may potentially crash but should not bring down the entire application.\n",
        "\n",
        "**Scalability across CPU cores:**\n",
        "\n",
        "If you need to fully utilize multiple CPU cores, multiprocessing is the better choice. It enables running tasks across all available CPU cores, unlike threads which may be bottlenecked by the GIL.\n",
        "\n",
        "Example:\n",
        "Large-scale data processing or performing computations that benefit from being distributed across multiple cores.\n",
        "\n",
        "**Bypassing the GIL:**\n",
        "\n",
        "The GIL restricts multithreaded Python programs from taking full advantage of multiple cores in CPU-bound tasks. By using multiprocessing, each process has its own GIL, allowing the program to make full use of multi-core systems.\n",
        "\n",
        "**Ideal scenarios for multiprocessing:**\n",
        "\n",
        "Heavy data processing tasks or numerical simulations.\n",
        "\n",
        "CPU-intensive operations such as machine learning model training, video encoding, or rendering.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vg9yWxVIp08P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison of Multithreading and Multiprocessing:**\n",
        "\n",
        "\n",
        "**Multithreading**\n",
        "\n",
        "I/O-bound tasks:\n",
        "Efficient for tasks involving file operations, network requests, or other I/O-related activities where waiting time is significant.\n",
        "\n",
        "Shared memory:\n",
        "hreads operate within the same memory space, facilitating easy data sharing and communication.\n",
        "\n",
        "Lightweight: Threads are less resource-intensive compared to processes.\n",
        "\n",
        "GIL impact: In Python, the Global Interpreter Lock (GIL) can hinder multithreading performance for CPU-bound tasks.\n",
        "\n",
        "Quick context switching: Switching between threads is typically faster due to shared memory.\n",
        "\n",
        "**Multiprocessing**\n",
        "\n",
        "CPU-bound tasks: Ideal for tasks requiring heavy computation, making full use of multiple CPU cores.\n",
        "\n",
        "Separate memory space: Each process runs in its own memory space, which helps prevent data corruption.\n",
        "\n",
        "Heavier: Processes consume more resources compared to threads.\n",
        "\n",
        "Bypasses GIL: Multiprocessing can effectively bypass the GIL in Python, enhancing performance for CPU-intensive tasks.\n",
        "\n",
        "Slower context switching: Switching between processes is slower due to isolated memory spaces.\n"
      ],
      "metadata": {
        "id": "iyDJ6-y6spm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
        "\n",
        "#Answer:\n",
        "\n",
        "A process pool in Python is a feature from libraries like multiprocessing that helps in managing and executing tasks across multiple worker processes in parallel. It creates a pool of processes and distributes tasks among them, allowing for efficient parallel processing. This is particularly useful for tasks that are CPU-bound, as it can leverage multiple CPU cores to improve performance.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "**Processes:**\n",
        "Independent execution units with their own memory. Unlike threads, processes don't share memory, so they run completely separately. Communication between them requires special techniques, like inter-process communication (IPC).\n",
        "\n",
        "**Pool of Processes:**\n",
        "Instead of creating and destroying processes for each task (which can be slow and resource-intensive), a fixed number of processes are pre-allocated and reused. When tasks are submitted, the pool assigns them to the available processes.\n",
        "\n",
        "**How a Process Pool Improves Efficiency:**\n",
        "\n",
        "**1.Optimized Resource Use:**\n",
        "\n",
        "A pool of processes is created at the start, which minimizes the overhead of constantly creating and destroying processes for each task.\n",
        "o\tTasks are assigned dynamically to free processes in the pool, ensuring CPU cores are utilized efficiently.\n",
        "\n",
        "**2.Concurrency:**\n",
        "\n",
        "Tasks can run in parallel across multiple CPU cores, which speeds up the execution of tasks that require intensive processing.\n",
        "\n",
        "**3.Simple Task Assignment:**\n",
        "\n",
        "Python’s multiprocessing.Pool offers easy-to-use methods, such as apply(), apply_async(), map(), and map_async() for submitting tasks to the pool.\n",
        "\n",
        "**4.Automatic Task Scheduling:**\n",
        "\n",
        "The process pool automatically distributes tasks to worker processes, ensuring that work is processed efficiently as soon as resources are available.\n",
        "\n"
      ],
      "metadata": {
        "id": "M-N49o4lsqd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example in Python:\n",
        "#Here’s an example that demonstrates using a process pool:\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "def square(num):\n",
        "    return num * num\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a process pool with 4 worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        # Distribute tasks to the pool\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "    print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvEHDyD8t0mG",
        "outputId": "6738b51b-329f-48c9-8059-60d1240b97c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Functions:**\n",
        "\n",
        "•\tPool.apply():\n",
        "Runs a function in one of the pool's processes and waits for it to finish.\n",
        "\n",
        "•\tPool.apply_async():\n",
        "Asynchronously runs a function, allowing other code to run while waiting for the result.\n",
        "\n",
        "•\tPool.map():\n",
        "Applies a function to every item in a list or iterable, distributing the work across the pool.\n",
        "\n",
        "•\tPool.map_async():\n",
        "An asynchronous version of map().\n",
        "\n",
        "**Benefits of Using a Process Pool:**\n",
        "\n",
        "**Lower Overhead:**\n",
        "\n",
        "By reusing the same processes, you avoid the costs associated with creating new processes each time a task is run.\n",
        "\n",
        "**Parallel Execution:**\n",
        "\n",
        "By distributing tasks across multiple processes, you can take advantage of multicore CPUs to run tasks faster.\n",
        "\n",
        "**Simplified Parallel Processing:**\n",
        "\n",
        "Python’s multiprocessing module makes it easier to manage parallel processing without dealing with complex process management code.\n",
        "\n",
        "This approach is particularly effective for CPU-bound tasks, as each process runs independently with its own Python interpreter, bypassing the limitations of Python’s Global Interpreter Lock (GIL)."
      ],
      "metadata": {
        "id": "YdpoiaWLt_3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3. Explain what multiprocessing is and why it is used in Python programs.\n",
        "\n",
        "#Answer:\n",
        "\n",
        "Multiprocessing in Python refers to a method where multiple processes run concurrently, taking advantage of multiple CPU cores to handle different tasks simultaneously. Unlike threads, each process in multiprocessing operates in its own memory space, which makes it especially useful for tasks that require intensive computation or need to be executed in parallel.\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "**Processes:**\n",
        "\n",
        "In multiprocessing, each process has its own separate memory and Python interpreter instance, avoiding the limitations of Python's Global Interpreter Lock (GIL), which can hinder multithreading performance.\n",
        "Parallel Execution: Processes can run in parallel on different CPU cores, enabling multiple tasks to be executed at the same time.\n",
        "\n",
        "**Memory Isolation:**\n",
        "\n",
        "Each process operates independently, ensuring that if one process crashes, it doesn't affect others, enhancing stability.\n",
        "\n",
        "**Inter-process Communication (IPC):**\n",
        "\n",
        "Although processes are isolated, they can communicate with each other using techniques like pipes, queues, or shared memory, though this is more complex compared to threading.\n",
        "\n",
        "**Why is it used in Python?**\n",
        "1.\tHandling CPU-bound tasks: Multiprocessing is highly effective for tasks that require heavy CPU usage, such as large computations or complex data processing. By distributing these tasks across multiple cores, programs can run more efficiently.\n",
        "\n",
        "2.\tAvoiding the GIL: Python’s Global Interpreter Lock (GIL) restricts the execution of multiple threads within a single process, limiting their ability to run simultaneously. Multiprocessing bypasses this issue by running each process in its own interpreter, allowing full parallelism.\n",
        "\n",
        "3.\tImproved Performance: For programs that can split tasks into smaller, independent units, multiprocessing can greatly reduce execution time by allowing these units to run on different cores at the same time.\n",
        "\n",
        "4.\tBetter Scalability: For larger applications that need to handle significant workloads, multiprocessing allows Python programs to manage more tasks concurrently without performance bottlenecks.\n",
        "\n",
        "\n",
        "**Common Applications:**\n",
        "\n",
        "•\tLarge-scale data analysis or processing.\n",
        "\n",
        "•\tMedia-related tasks such as image manipulation, video processing, or encoding.\n",
        "\n",
        "•\tComputational tasks like simulations or mathematical operations.\n",
        "\n",
        "•\tWeb scraping or data collection, especially when dealing with multiple sources at once.\n",
        "\n",
        "Python's multiprocessing module provides an easy-to-use interface for implementing parallel processing in applications, helping to improve performance by distributing work across multiple processors.\n",
        "\n"
      ],
      "metadata": {
        "id": "lTFspa-iuzqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4.Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.\n",
        "\n",
        "#Answer:\n",
        "\n",
        "a Python program that uses multithreading with a threading.Lock to avoid race conditions. One thread adds numbers to a shared list, and another thread removes numbers from the list. The lock ensures that only one thread can access the list at a time, preventing inconsistencies."
      ],
      "metadata": {
        "id": "8idJ2Q7OwTZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list that will be accessed by multiple threads\n",
        "shared_data = []\n",
        "\n",
        "# A lock to synchronize access to the shared list\n",
        "data_lock = threading.Lock()\n",
        "\n",
        "# Event to signal termination\n",
        "termination_event = threading.Event()\n",
        "\n",
        "# Function that adds random numbers to the shared list\n",
        "def producer():\n",
        "    while not termination_event.is_set():\n",
        "        num = random.randint(1, 100)  # Generate a random number\n",
        "        with data_lock:  # Acquire lock before modifying the list\n",
        "            shared_data.append(num)\n",
        "            print(f\"Produced: {num}, Current List: {shared_data}\")\n",
        "        time.sleep(random.uniform(0.1, 1))  # Sleep for a random interval\n",
        "\n",
        "# Function that removes numbers from the shared list\n",
        "def consumer():\n",
        "    while not termination_event.is_set():\n",
        "        with data_lock:  # Acquire lock before accessing the list\n",
        "            if shared_data:\n",
        "                removed_num = shared_data.pop(0)\n",
        "                print(f\"Consumed: {removed_num}, Current List: {shared_data}\")\n",
        "        time.sleep(random.uniform(0.1, 1))  # Sleep for a random interval\n",
        "\n",
        "# Create and start the threads\n",
        "producer_thread = threading.Thread(target=producer)\n",
        "consumer_thread = threading.Thread(target=consumer)\n",
        "\n",
        "producer_thread.start()\n",
        "consumer_thread.start()\n",
        "\n",
        "# Run the threads for a limited time\n",
        "time.sleep(10)  # Let the threads run for 10 seconds\n",
        "\n",
        "# Signal the threads to terminate\n",
        "termination_event.set()\n",
        "\n",
        "# Wait for the threads to finish\n",
        "producer_thread.join()\n",
        "consumer_thread.join()\n",
        "\n",
        "print(\"Threads have been terminated gracefully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6jp7Ckqt65a",
        "outputId": "5b820365-fa2d-4ffb-b59e-e2a031e1b023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Produced: 96, Current List: [77, 98, 29, 96]\n",
            "Produced: 24, Current List: [24]\n",
            "Consumed: 24, Current List: []\n",
            "Produced: 88, Current List: [88]\n",
            "Produced: 52, Current List: [88, 52]\n",
            "Consumed: 88, Current List: [52]\n",
            "Produced: 8, Current List: [52, 8]\n",
            "Consumed: 52, Current List: [8]\n",
            "Produced: 95, Current List: [8, 95]\n",
            "Produced: 91, Current List: [8, 95, 91]\n",
            "Consumed: 8, Current List: [95, 91]\n",
            "Consumed: 95, Current List: [91]\n",
            "Consumed: 91, Current List: []\n",
            "Produced: 32, Current List: [32]\n",
            "Consumed: 32, Current List: []\n",
            "Produced: 85, Current List: [85]\n",
            "Consumed: 85, Current List: []\n",
            "Produced: 93, Current List: [93]\n",
            "Consumed: 93, Current List: []\n",
            "Produced: 45, Current List: [45]\n",
            "Consumed: 45, Current List: []\n",
            "Produced: 47, Current List: [47]\n",
            "Consumed: 47, Current List: []\n",
            "Produced: 37, Current List: [37]\n",
            "Consumed: 37, Current List: []\n",
            "Produced: 28, Current List: [28]\n",
            "Produced: 22, Current List: [28, 22]\n",
            "Consumed: 28, Current List: [22]\n",
            "Produced: 72, Current List: [22, 72]\n",
            "Consumed: 22, Current List: [72]\n",
            "Produced: 60, Current List: [72, 60]\n",
            "Consumed: 72, Current List: [60]\n",
            "Produced: 10, Current List: [60, 10]\n",
            "Consumed: 60, Current List: [10]\n",
            "Consumed: 10, Current List: []\n",
            "Produced: 42, Current List: [42]\n",
            "Produced: 20, Current List: [42, 20]\n",
            "Consumed: 42, Current List: [20]\n",
            "Produced: 5, Current List: [20, 5]\n",
            "Consumed: 20, Current List: [5]\n",
            "Produced: 98, Current List: [5, 98]\n",
            "Consumed: 5, Current List: [98]\n",
            "Produced: 35, Current List: [98, 35]\n",
            "Consumed: 98, Current List: [35]\n",
            "Consumed: 35, Current List: []\n",
            "Produced: 61, Current List: [61]\n",
            "Produced: 46, Current List: [61, 46]\n",
            "Produced: 42, Current List: [61, 46, 42]\n",
            "Consumed: 61, Current List: [46, 42]\n",
            "Produced: 55, Current List: [46, 42, 55]\n",
            "Consumed: 46, Current List: [42, 55]\n",
            "Produced: 32, Current List: [42, 55, 32]\n",
            "Produced: 87, Current List: [42, 55, 32, 87]\n",
            "Consumed: 42, Current List: [55, 32, 87]\n",
            "Produced: 80, Current List: [55, 32, 87, 80]\n",
            "Consumed: 55, Current List: [32, 87, 80]\n",
            "Produced: 11, Current List: [32, 87, 80, 11]\n",
            "Produced: 36, Current List: [32, 87, 80, 11, 36]\n",
            "Consumed: 32, Current List: [87, 80, 11, 36]\n",
            "Consumed: 87, Current List: [80, 11, 36]\n",
            "Consumed: 80, Current List: [11, 36]\n",
            "Produced: 33, Current List: [11, 36, 33]\n",
            "Produced: 3, Current List: [11, 36, 33, 3]\n",
            "Produced: 73, Current List: [11, 36, 33, 3, 73]\n",
            "Consumed: 11, Current List: [36, 33, 3, 73]\n",
            "Threads have been terminated gracefully.\n",
            "Produced: 72, Current List: [36, 33, 3, 73, 72]\n",
            "Consumed: 36, Current List: [33, 3, 73, 72]\n",
            "Consumed: 33, Current List: [3, 73, 72]\n",
            "Produced: 95, Current List: [3, 73, 72, 95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKdDNxsWxkyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How It Works:**\n",
        "1.\tShared List: shared_data is the common list accessed by both threads.\n",
        "2.\tLock Mechanism: data_lock ensures that when one thread is modifying the list, the other has to wait, preventing inconsistent data.\n",
        "3.\tProducer: The producer function creates a random number and appends it to the list. The lock ensures this happens safely without interference from other threads.\n",
        "4.\tConsumer: The consumer function removes the first item from the list, but only if the list isn't empty. It also uses the lock to ensure safe removal.\n",
        "5.\tMultithreading: Two threads are created, one running the producer and the other running the consumer. These threads operate concurrently, continuously adding and removing items from the list.\n",
        "\n",
        "This solution ensures thread-safe operations on the shared list using threading.Lock to avoid race conditions.\n"
      ],
      "metadata": {
        "id": "7Qw9TV4xx-qY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
        "\n",
        "#Answer:\n",
        "\n",
        "In Python, safely sharing data between threads and processes is important to avoid problems such as race conditions, deadlocks, or data corruption. Depending on whether you're working with threads or processes, Python provides different mechanisms to achieve safe and efficient communication and synchronization.\n",
        "\n",
        "**1. Threads (using the threading module)**\n",
        "\n",
        "Threads share the same memory space, so proper synchronization is essential to prevent simultaneous access to shared data.\n",
        "\n",
        "**a. Locks (Mutex)**\n",
        "\n",
        "A Lock ensures that only one thread can access a shared resource at a time, preventing race conditions.\n",
        "\n",
        "**Usage:**\n",
        "\n",
        "lock.acquire(): A thread gains exclusive access to the resource.\n",
        "\n",
        "lock.release():\n",
        "The thread releases the lock after the operation is complete.\n"
      ],
      "metadata": {
        "id": "C-b2pWmkyOFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from threading import Lock\n",
        "\n",
        "lock = Lock()\n",
        "shared_data = 0\n",
        "\n",
        "def safe_increment():\n",
        "    global shared_data\n",
        "    with lock:\n",
        "        shared_data += 1\n"
      ],
      "metadata": {
        "id": "oOLQj8lLz4av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. RLock (Reentrant Lock)**\n",
        "\n",
        "An RLock is similar to a regular Lock, but it allows the same thread to acquire the lock multiple times without causing a deadlock, useful for recursive calls or complex synchronization scenarios.\n"
      ],
      "metadata": {
        "id": "CxOrJAH2z_XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from threading import RLock\n",
        "\n",
        "rlock = RLock()\n",
        "\n",
        "def synchronized_function():\n",
        "    with rlock:\n",
        "        # Critical section\n"
      ],
      "metadata": {
        "id": "efHbnfSP0loW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Condition Variables**\n",
        "\n",
        "Condition is used when threads need to wait for a certain condition to be met before proceeding, often in combination with a Lock.\n"
      ],
      "metadata": {
        "id": "T8BaPiqf0nYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from threading import Condition\n",
        "\n",
        "condition = Condition()\n",
        "\n",
        "def consumer():\n",
        "    with condition:\n",
        "        condition.wait()  # Wait until notified\n",
        "        # Process data\n",
        "\n",
        "def producer():\n",
        "    with condition:\n",
        "        # Add data\n",
        "        condition.notify()  # Notify waiting threads\n"
      ],
      "metadata": {
        "id": "3miJJLJC0yRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Thread-safe Queues**\n",
        "\n",
        "The Queue class from the queue module provides thread-safe mechanisms for communication between threads. It manages locking automatically, making it a safe option for passing data between threads.\n"
      ],
      "metadata": {
        "id": "krvNbfys03es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from queue import Queue\n",
        "from threading import Thread\n",
        "\n",
        "q = Queue()\n",
        "\n",
        "def producer():\n",
        "    for i in range(5):\n",
        "        q.put(i)\n",
        "\n",
        "def consumer():\n",
        "    while True:\n",
        "        item = q.get()\n",
        "        print(item)\n",
        "        q.task_done()\n",
        "\n",
        "Thread(target=producer).start()\n",
        "Thread(target=consumer).start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTHHpxvg1EoW",
        "outputId": "0f1dcaab-7feb-46b0-9b24-2372bae2f4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmzueAwh1HMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Events**\n",
        "\n",
        "An Event is used to manage signaling between threads. A thread can wait until an event is set, allowing synchronization without polling.\n"
      ],
      "metadata": {
        "id": "0TG4gsKO1Mg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from threading import Event\n",
        "\n",
        "event = Event()\n",
        "\n",
        "def wait_for_event():\n",
        "    event.wait()  # Blocks until the event is set\n",
        "    print(\"Event triggered\")\n",
        "\n",
        "def trigger_event():\n",
        "    event.set()  # Signals the event\n"
      ],
      "metadata": {
        "id": "udG9R6pr1Qse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5ZN4Gbe1TEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Processes (using the multiprocessing module)**\n",
        "\n",
        "Since processes have separate memory spaces, sharing data between them requires different mechanisms than threads.\n",
        "\n",
        "**a. Multiprocessing Queues**\n",
        "\n",
        "multiprocessing.Queue is a process-safe queue, allowing multiple processes to exchange data safely.\n"
      ],
      "metadata": {
        "id": "4KekoWgu1XAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from multiprocessing import Queue, Process\n",
        "\n",
        "q = Queue()\n",
        "\n",
        "def producer():\n",
        "    q.put(\"data\")\n",
        "\n",
        "def consumer():\n",
        "    print(q.get())\n",
        "\n",
        "p1 = Process(target=producer)\n",
        "p2 = Process(target=consumer)\n",
        "p1.start()\n",
        "p2.start()\n",
        "p1.join()\n",
        "p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKgjh2kj1hlG",
        "outputId": "c41b9c35-a665-45fe-eeaf-5549100963cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHGBCI441jd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Pipes**\n",
        "\n",
        "Pipe is another way to establish communication between two processes.It creates two connected ends (connections) that can send and receive data.\n"
      ],
      "metadata": {
        "id": "wfjwn1HM1nLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from multiprocessing import Pipe, Process\n",
        "\n",
        "def producer(conn):\n",
        "    conn.send(\"data\")\n",
        "\n",
        "def consumer(conn):\n",
        "    print(conn.recv())\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "\n",
        "p1 = Process(target=producer, args=(child_conn,))\n",
        "p2 = Process(target=consumer, args=(parent_conn,))\n",
        "p1.start()\n",
        "p2.start()\n",
        "p1.join()\n",
        "p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cVBfIj1w9m",
        "outputId": "3fcd7a5d-2a5d-4ab8-c732-163c87031daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lv-lmGr51zA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Shared Memory (Values and Arrays)**\n",
        "\n",
        "You can use multiprocessing.Value and multiprocessing.Array to share simple data types and arrays between processes. These shared objects are stored in shared memory and can be accessed by multiple processes, with an internal lock to prevent simultaneous access.\n"
      ],
      "metadata": {
        "id": "pT56Zasz148s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from multiprocessing import Value, Process\n",
        "\n",
        "shared_value = Value('i', 0)  # 'i' represents an integer\n",
        "\n",
        "def increment():\n",
        "    with shared_value.get_lock():  # Ensure thread-safe access\n",
        "        shared_value.value += 1\n",
        "\n",
        "p = Process(target=increment)\n",
        "p.start()\n",
        "p.join()\n"
      ],
      "metadata": {
        "id": "qbx7SwgS1-eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5IDcrY8D2AbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. Managers (for Complex Data Structures)**\n",
        "\n",
        "multiprocessing.Manager offers a high-level approach for sharing complex data types like lists, dictionaries, and more between processes. It internally manages synchronization for safe access.\n"
      ],
      "metadata": {
        "id": "ufNR3S4X2D_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from multiprocessing import Manager, Process\n",
        "\n",
        "def worker(shared_dict):\n",
        "    shared_dict['key'] = 'value'\n",
        "\n",
        "manager = Manager()\n",
        "shared_dict = manager.dict()\n",
        "\n",
        "p = Process(target=worker, args=(shared_dict,))\n",
        "p.start()\n",
        "p.join()\n",
        "\n",
        "print(shared_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBYgRSXD2LO4",
        "outputId": "90bd4624-388b-46bb-8b05-083c02706968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'key': 'value'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-W0mt4vL2OGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e. Locks for Processes**\n",
        "\n",
        "multiprocessing.Lock is used to ensure that only one process can access a shared resource at any given time, similar to threading.Lock.\n"
      ],
      "metadata": {
        "id": "S336tnFh2TQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "from multiprocessing import Lock, Process\n",
        "\n",
        "lock = Lock()\n",
        "\n",
        "def critical_section():\n",
        "    with lock:\n",
        "        print(\"Accessing critical section\")\n",
        "\n",
        "p = Process(target=critical_section)\n",
        "p.start()\n",
        "p.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJtXMBRN2YKM",
        "outputId": "46003f9e-7f0b-45fe-f321-f84ac081a25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accessing critical section\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-jLH5462bb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "•\tFor threads, synchronization tools include Lock, RLock, Condition, Queue, and Event, which are used to manage safe access to shared memory.\n",
        "\n",
        "•\tFor processes, tools such as multiprocessing.Queue, Pipe, Value, Array, Manager, and Lock enable safe data sharing between processes with isolated memory spaces.\n",
        "\n",
        "These tools are designed to coordinate data access safely, preventing problems like race conditions or inconsistent states in concurrent programming.\n"
      ],
      "metadata": {
        "id": "N8r-174Z2erO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
        "\n",
        "#Answer:\n",
        "\n",
        "The Importance of Exception Handling in Concurrent Programs\n",
        "Handling exceptions in concurrent programming is vital for several reasons, especially in Python. Here are the key considerations:\n",
        "\n",
        "1.\tSystem Reliability: When exceptions occur in one thread or process without being handled, they can lead to crashes or unpredictable behavior in the entire application. Proper handling ensures that errors can be managed without affecting the overall stability of the system.\n",
        "\n",
        "2.\tData Integrity: Concurrent programs often manipulate shared data. Unhandled exceptions can leave shared resources in an inconsistent state, leading to data corruption or unexpected outcomes. Exception handling helps maintain data consistency.\n",
        "\n",
        "3.\tError Diagnosis and Logging: Effectively managing exceptions allows for better error reporting and logging, which are crucial for troubleshooting issues in complex concurrent applications.\n",
        "\n",
        "4.\tResource Management: Exceptions can arise during resource allocation (e.g., file handles or network connections). Without appropriate handling, these resources might not be released properly, resulting in leaks and performance degradation.\n",
        "\n",
        "5.\tUser Experience: In applications with user interfaces, unhandled exceptions can degrade user experience. Proper exception handling can enable graceful error management or provide clear error messages to users.\n",
        "\n",
        "\n",
        "**Techniques for Handling Exceptions in Python Concurrent Programming**\n",
        "\n",
        "Python provides various methods for managing exceptions in concurrent programming. Here are some commonly used techniques:\n",
        "\n",
        "**1.Threading:**\n",
        "\n",
        "Implement try-except blocks within the target function of a thread to capture exceptions specific to that thread. The Thread class allows overriding the run method to include exception handling.\n"
      ],
      "metadata": {
        "id": "8PBaY7m03Ez8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        # Simulate work\n",
        "        raise ValueError(\"An error occurred\")\n",
        "    except Exception as e:\n",
        "        print(f\"Thread exception: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCZ_6VX432hx",
        "outputId": "000b69f0-3f61-4865-ea8b-7d3768f71d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread exception: An error occurred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZREc6ywx33bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Multiprocessing:**\n",
        "\n",
        "In the multiprocessing module, exceptions caught in a child process need to be communicated back to the parent process. You can use a Queue to transfer exceptions.\n"
      ],
      "metadata": {
        "id": "S2v8d_7s3-pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def worker(queue):\n",
        "    try:\n",
        "        raise ValueError(\"An error occurred in process\")\n",
        "    except Exception as e:\n",
        "        queue.put(e)\n",
        "\n",
        "queue = Queue()\n",
        "process = Process(target=worker, args=(queue,))\n",
        "process.start()\n",
        "process.join()\n",
        "\n",
        "if not queue.empty():\n",
        "    print(f\"Process exception: {queue.get()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8U5tGTM4HE9",
        "outputId": "6645cc51-f4a6-4c51-bbd5-950fdbb3190b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process exception: An error occurred in process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Using Future Objects with concurrent.futures:**\n",
        "\n",
        "When leveraging the concurrent.futures module, you can handle exceptions by calling the result() method on a Future object. If the function encounters an exception, it will be raised when you call result().\n"
      ],
      "metadata": {
        "id": "4jsLm8IM4RGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def worker():\n",
        "    raise ValueError(\"An error occurred\")\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(worker)\n",
        "    try:\n",
        "        future.result()\n",
        "    except Exception as e:\n",
        "        print(f\"Future exception: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP5sPUYu4X_B",
        "outputId": "3190b72f-fdc8-45f2-e7f3-95035d400cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Future exception: An error occurred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7E1VtJ0M4Ihk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Asynchronous Programming with Asyncio:**\n",
        "\n",
        "In asynchronous programming using asyncio, exceptions can be managed with try-except blocks within asynchronous functions. The asyncio library also provides the ability to gather multiple coroutines and handle exceptions collectively.\n"
      ],
      "metadata": {
        "id": "UMQr74SB4eod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def worker():\n",
        "    raise ValueError(\"An error occurred in async function\")\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        await worker()\n",
        "    except Exception as e:\n",
        "        print(f\"Async exception: {e}\")\n",
        "\n",
        "asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "ijNncbln4leG",
        "outputId": "286d164a-55b2-4211-faa7-f022ca512763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-dd80114dac19>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Async exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Async exception: An error occurred in async function\n"
      ],
      "metadata": {
        "id": "VLo5bIBj5UMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Using Context Managers:**\n",
        "\n",
        "Context managers are useful for ensuring resources are properly managed, even when exceptions occur. This approach is especially beneficial for file operations or network connections.\n"
      ],
      "metadata": {
        "id": "W8u-UEo55hT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from contextlib import contextmanager\n",
        "\n",
        "@contextmanager\n",
        "def managed_resource():\n",
        "    try:\n",
        "        # Acquire resource\n",
        "        yield\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in resource management: {e}\")\n",
        "    finally:\n",
        "        # Release resource\n",
        "\n",
        "with managed_resource():\n",
        "    raise ValueError(\"An error during resource usage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "OrjnqkWu5oXx",
        "outputId": "0f496044-c438-419f-c563-2e197534e78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'finally' statement on line 10 (<ipython-input-19-14c1b7e5d185>, line 13)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-14c1b7e5d185>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    with managed_resource():\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'finally' statement on line 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Effective exception handling in concurrent programs is crucial for ensuring robustness and maintainability. By utilizing the various techniques available in Python, developers can manage errors efficiently, safeguarding the integrity and reliability of their applications in complex concurrent environments."
      ],
      "metadata": {
        "id": "TRkKM7gX5rZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "\n",
        "#Answer:\n",
        "\n",
        "Below is the code:"
      ],
      "metadata": {
        "id": "y88dERBp55nI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "def compute_factorial(n):\n",
        "    \"\"\"Return the factorial of the given number.\"\"\"\n",
        "    return math.factorial(n)\n",
        "\n",
        "def main():\n",
        "    # Create a thread pool for concurrent execution\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Prepare tasks to compute factorials for numbers 1 to 10\n",
        "        tasks = {executor.submit(compute_factorial, i): i for i in range(1, 11)}\n",
        "\n",
        "        # Process results as tasks complete\n",
        "        for future in concurrent.futures.as_completed(tasks):\n",
        "            number = tasks[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "                print(f'Factorial of {number} is {result}.')\n",
        "            except Exception as e:\n",
        "                print(f'Error calculating factorial for {number}: {e}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ-mzktg6Q5D",
        "outputId": "b90d46bb-4295-4bc9-a16e-7e2ed10272b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 5 is 120.\n",
            "Factorial of 7 is 5040.\n",
            "Factorial of 1 is 1.\n",
            "Factorial of 8 is 40320.\n",
            "Factorial of 2 is 2.\n",
            "Factorial of 9 is 362880.\n",
            "Factorial of 3 is 6.\n",
            "Factorial of 4 is 24.\n",
            "Factorial of 10 is 3628800.\n",
            "Factorial of 6 is 720.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/tokenize.py:527: RuntimeWarning: coroutine 'main' was never awaited\n",
            "  pseudomatch = _compile(PseudoToken).match(line, pos)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Breakdown:**\n",
        "\n",
        "1.\tImports: The program imports the necessary modules: concurrent.futures for thread management and math for calculating factorials.\n",
        "2.\tFactorial Function: The compute_factorial function takes an integer n and returns its factorial using math.factorial().\n",
        "3.\tMain Function:\n",
        "o\tA ThreadPoolExecutor is instantiated with a context manager, which ensures proper resource handling.\n",
        "o\tA dictionary comprehension submits tasks to compute the factorials of numbers from 1 to 10, where the keys are Future objects, and the values are the respective numbers.\n",
        "4.\tHandling Results: Using concurrent.futures.as_completed(), the program processes each completed task. It retrieves the result and prints it.\n",
        "5.\tError Handling: Any errors that occur during the computation are caught and displayed.\n",
        "Running the Program:\n",
        "1.\tSave the code to a file, such as factorial_thread_pool.py.\n",
        "2.\tExecute the script using Python 3:\n",
        "bash\n",
        "python factorial_thread_pool.py\n",
        "\n",
        "You will see the factorials of the numbers from 1 to 10 printed in the order they are computed.\n"
      ],
      "metadata": {
        "id": "JJ-7xqFH6a_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
        "\n",
        "#Answer:\n",
        "\n",
        "Below is the code:"
      ],
      "metadata": {
        "id": "NUOy0EQd6lqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def compute_square(number):\n",
        "    \"\"\"Calculate the square of a given number.\"\"\"\n",
        "    return number ** 2\n",
        "\n",
        "def calculate_squares_with_pool(pool_size):\n",
        "    \"\"\"Use a multiprocessing pool to compute squares of numbers from 1 to 10.\"\"\"\n",
        "    with multiprocessing.Pool(processes=pool_size) as pool:\n",
        "        # Apply the compute_square function to the range of numbers\n",
        "        results = pool.map(compute_square, range(1, 11))\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [2, 4, 8]\n",
        "\n",
        "    for size in pool_sizes:\n",
        "        start_time = time.time()  # Record the start time\n",
        "        results = calculate_squares_with_pool(size)  # Perform the computation\n",
        "        end_time = time.time()    # Record the end time\n",
        "\n",
        "        # Output the pool size, results, and time taken\n",
        "        print(f\"Using pool size: {size}, Squares: {results}, Duration: {end_time - start_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F_UUi4N63I-",
        "outputId": "31db42cd-ba31-4037-89a3-0e298aefafb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pool size: 2, Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Duration: 0.0504 seconds\n",
            "Using pool size: 4, Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Duration: 0.0618 seconds\n",
            "Using pool size: 8, Squares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Duration: 0.1128 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bR6bN3VL6RX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "1.Function Definition:\n",
        "\n",
        "square(n): This function computes the square of the input number.\n",
        "compute_squares(pool_size): This function initializes a Pool with the specified number of processes and maps the square function to the range of numbers from 1 to 10.\n",
        "\n",
        "2.Timing:\n",
        "\n",
        "The time taken to perform the computation is measured using time.time() before and after calling compute_squares.\n",
        "\n",
        "3.Main Block:\n",
        "\n",
        "The main block of the code iterates over different pool sizes (2, 4, and 8) and prints the results along with the time taken for each pool size.\n"
      ],
      "metadata": {
        "id": "DkhOfCKe7lvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================The End==============================="
      ],
      "metadata": {
        "id": "LaNM4rsP8C1C"
      }
    }
  ]
}